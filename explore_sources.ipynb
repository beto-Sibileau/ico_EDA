{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Source covid19](https://www.covid19india.org/)\n",
    "https://api.covid19india.org/\n",
    "\n",
    "Recommended approach from doc: json parsing of V4 endopoints\n",
    "\t\t\n",
    "| Status | Link to API | Description |\n",
    "| --- | --- | --- |\n",
    "| <img src=https://github.githubassets.com/images/icons/emoji/unicode/1f49a.png width=\"20\"> | https://api.covid19india.org/v4/min/timeseries.min.json | Daily numbers across C,R,D and Tested per state (historical data) |\n",
    "| <img src=https://github.githubassets.com/images/icons/emoji/unicode/1f49a.png width=\"20\"> | https://api.covid19india.org/v4/min/data.min.json | Current day numbers across districts and states |\n",
    "| <img src=https://github.githubassets.com/images/icons/emoji/unicode/1f49a.png width=\"20\"> | https://api.covid19india.org/v4/min/data-all.min.json | Per day numbers across districts and states - consider using timeseries in place of this. This is a huge file and is a mix of timeseries and data.min.json |\n",
    "\n",
    "**Doc Note**: *Please consider using the above endpoints for all your data needs. All the data we show on the website is fuelled by the above endpoints.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time-series structure\n",
    "Per state level time-series (*conf., rec., dec., tested, vacc.*)\n",
    "\n",
    "https://api.covid19india.org/documentation/timeseries.min.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.covid19india.org/v4/min/timeseries.min.json\"\n",
    "response_ts = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json and normalize\n",
    "start_time = time.time()\n",
    "wide_ts_df = pd.json_normalize(response_ts.json())\n",
    "total_sec = time.time() - start_time\n",
    "print(f\"{round(total_sec,1)} secs execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build long format from column names structure (renames as desired)\n",
    "long_ts_df = wide_ts_df.columns.str.split(\".\", expand=True).droplevel(1).to_frame(\n",
    "    index=False, name=[\"state\", \"time_period\", \"obs_type\", \"obs_cat\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add values from series\n",
    "long_ts_df[\"val\"] = wide_ts_df.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "\n",
    "- no key for `delta` should take the neareast previous, eg: `AN, 2020-04-10, delta, recovered` not present means `AN, 2020-04-09, delta, recovered: 10` value has not changed\n",
    "- `delta7` means \"*7-day moving average*\" --> calculations confirmed it's last 7 days **sum** rather than **avg**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "long_ts_df.loc[30:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f\"Total data points number: {len(long_ts_df.state)}\")\n",
    "states = long_ts_df.state.unique()\n",
    "print(f\"{len(long_ts_df.state.unique())} states:\\n{states}\")\n",
    "types = long_ts_df.obs_type.unique()\n",
    "print(f\"obs_type:\\n{types}\")\n",
    "categs = long_ts_df.obs_cat.unique()\n",
    "print(f\"obs_cat:\\n{categs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time-series data vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "from jupyter_dash import JupyterDash\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect proxy configuration for JupyterHub or Binder\n",
    "JupyterDash.infer_jupyter_proxy_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropdowns: state, obs_type, obs_cat, time_period\n",
    "dd_st = dcc.Dropdown(\n",
    "    id=\"my_st\",\n",
    "    options=[\n",
    "        {\"label\": value, \"value\": key}\n",
    "        for key, value in zip(states, states)\n",
    "    ],\n",
    "    value='AN'\n",
    ")\n",
    "dd_type = dcc.Dropdown(\n",
    "    id=\"my_typ\",\n",
    "    options=[\n",
    "        {\"label\": value, \"value\": key}\n",
    "        for key, value in zip(types, types)\n",
    "    ],\n",
    "    value='delta7'\n",
    ")\n",
    "dd_cat = dcc.Dropdown(\n",
    "    id=\"my_cat\",\n",
    "    options=[\n",
    "        {\"label\": value, \"value\": key}\n",
    "        for key, value in zip(categs, categs)\n",
    "    ],\n",
    "    value='confirmed'\n",
    ")\n",
    "time_ps = sorted(long_ts_df.time_period.unique(), reverse=True)\n",
    "dd_time = dcc.Dropdown(\n",
    "    id=\"my_time\",\n",
    "    options=[\n",
    "        {\"label\": value, \"value\": key}\n",
    "        for key, value in zip(time_ps, time_ps)\n",
    "    ],\n",
    "    value='2021-05-01'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "# Build App\n",
    "app = JupyterDash(__name__, external_stylesheets=external_stylesheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# App Layout\n",
    "app.layout = html.Div([\n",
    "    html.H2(\"Indian States Covid Time-Series\"),\n",
    "    html.H6(\"Browse by State, type and category of obs_values and cut-off time\"),\n",
    "    html.Div([\n",
    "        html.Div(\n",
    "            [\"Select State\", dd_st],\n",
    "            style={'width': '24%', 'display': 'inline-block'},\n",
    "        ),\n",
    "        html.Div(\n",
    "            [\"Select type\", dd_type],\n",
    "            style={'width': '24%', 'display': 'inline-block'},\n",
    "        ),\n",
    "        html.Div(\n",
    "            [\"Select category\", dd_cat],\n",
    "            style={'width': '24%', 'display': 'inline-block'},\n",
    "        ),\n",
    "        html.Div(\n",
    "            [\"Select cut-off time\", dd_time],\n",
    "            style={'width': '24%', 'display': 'inline-block'},\n",
    "        ),\n",
    "    ]),\n",
    "    html.Br(),\n",
    "    dcc.Graph(id='time-series')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback to update graph\n",
    "@app.callback(\n",
    "    Output(\"time-series\", \"figure\"),\n",
    "    Input(\"my_st\", \"value\"),\n",
    "    Input(\"my_typ\", \"value\"),\n",
    "    Input(\"my_cat\", \"value\"),\n",
    "    Input(\"my_time\", \"value\"),\n",
    ")\n",
    "def query_2_plot(state, obs_type, obs_cat, co_time):\n",
    "    # return all times if co_time None\n",
    "    co_time = co_time if co_time else long_ts_df.time_period.min()\n",
    "    # don't return plot if missing values for query\n",
    "    if any([not state, not obs_type, not obs_cat]):\n",
    "        return {}\n",
    "    else:\n",
    "        query = \"state == @state & obs_type == @obs_type & obs_cat == @obs_cat & time_period > @co_time\"\n",
    "        fig = px.line(\n",
    "            long_ts_df.query(query),\n",
    "            x=\"time_period\",\n",
    "            y=\"val\",\n",
    "            line_shape=\"spline\",\n",
    "        ).update_traces(mode=\"lines+markers\")\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run app and display result inline in the notebook\n",
    "app.run_server(mode='inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Data-all\" data structure\n",
    "Described as: *Per day numbers across states and districts - consider using timeseries in place of this -. This is a huge file and is a mix of time-series and current day data*\n",
    "\n",
    "No documentantion @https://api.covid19india.org/\n",
    "\n",
    "**Note**: time-series data don't go into district as descripted. Is state time-series and current day data enough?\n",
    "- Actually I would need time-series at district level to go into *delta14_7* $\\rightarrow$ exploration below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.covid19india.org/v4/min/data-all.min.json\"\n",
    "response_all = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our aim here --> districts delta confirmed if present for the previous week --> delta14_7\n",
    "def conf_ds_deltaX_Y(json_resp, x=14, y=7):\n",
    "    '''\n",
    "    Json normalize from json_resp is time-processing unfeasible\n",
    "    Thus, extract only 'delta confirmed' for all districts previous week\n",
    "    :param json_resp: json response from 'data-all' Covid19 India API\n",
    "    :param x: lower limit number of days (integer)\n",
    "    :param y: upper limit number of days (integer)\n",
    "    :return: truncated json, all districts data restricted to: prev. week delta confirmed\n",
    "    '''\n",
    "    # reported days series\n",
    "    dates = pd.Series(list(json_resp.keys()))\n",
    "    # latest reported date assumed equal to all districts\n",
    "    last_date = pd.to_datetime(dates).max()\n",
    "    # filter range of days\n",
    "    cut_date_0 = (last_date - pd.to_timedelta(x, unit='d')).strftime('%Y-%m-%d')\n",
    "    cut_date_1 = (last_date - pd.to_timedelta(y, unit='d')).strftime('%Y-%m-%d')\n",
    "    filter_x_y = (dates > cut_date_0) & (dates <= cut_date_1)\n",
    "    # loop through range of days and return data in nested dictionary\n",
    "    trunc_json = {}\n",
    "    for day in dates[filter_x_y]:\n",
    "        trunc_json[day] = {}\n",
    "        for st in json_resp[day]:\n",
    "            if 'districts' in json_resp[day][st]:\n",
    "                trunc_json[day][st] = {}\n",
    "                for ds in json_resp[day][st]['districts']:\n",
    "                    if 'delta' in json_resp[day][st]['districts'][ds]:\n",
    "                        if 'confirmed' in json_resp[day][st]['districts'][ds]['delta']:\n",
    "                            trunc_json[day][st][ds] = json_resp[day][st]['districts'][ds]['delta']['confirmed']\n",
    "    return trunc_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "trunc_json = conf_ds_deltaX_Y(response_all.json())\n",
    "total_sec = time.time() - start_time\n",
    "print(f\"{round(total_sec,1)} secs execution\")\n",
    "# normalize truncated json with range of days\n",
    "wide_ds_range_df = pd.json_normalize(trunc_json, sep='//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build long format from column names (renames as desired)\n",
    "long_ds_range_df = wide_ds_range_df.columns.str.split(\"//\", expand=True).to_frame(\n",
    "    index=False, name=[\"time_period\", \"state\", \"district\"]\n",
    ")\n",
    "# add delta confirmed values from series\n",
    "long_ds_range_df[\"val\"] = wide_ds_range_df.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_ds_range_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current day data structure\n",
    "State and details as of the current day: *contains information about districts*\n",
    "\n",
    "https://api.covid19india.org/documentation/v4_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.covid19india.org/v4/min/data.min.json\"\n",
    "response_data = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### State data\n",
    "We here parse data at state level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter state metadata and districts out from json data\n",
    "json_st = {\n",
    "    key_1: {\n",
    "        key_2: response_data.json()[key_1][key_2]\n",
    "        for key_2 in response_data.json()[key_1] if key_2 not in ['districts', 'meta']\n",
    "    } for key_1 in response_data.json()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json_st and normalize\n",
    "wide_st_df = pd.json_normalize(json_st)\n",
    "# build long format from column names structure (renames as desired)\n",
    "long_st_df = wide_st_df.columns.str.split(\".\", expand=True).to_frame(\n",
    "    index=False, name=[\"state\", \"obs_type\", \"obs_cat\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add values from series\n",
    "long_st_df[\"val\"] = wide_st_df.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "\n",
    "- Doc caveat: any **obs_cat** category under key `delta` won't be present if a state/district doesn't see a change in such category (eg: `recovered`) for the current day\n",
    "- Could any state/district not be even reported for the current day?\n",
    "- research `delta21_14` meaning\n",
    "- compute the `delta14_7` for situation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Use time-series to compute delta14_7 for states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter states delta confirmed for the previous week --> delta14_7\n",
    "def conf_st_deltaX_Y(st_ts_df, x=14, y=7):\n",
    "    '''\n",
    "    :param st_ts_df: state data timeseries Covid19 India API\n",
    "    :param x: lower limit number of days (integer)\n",
    "    :param y: upper limit number of days (integer)\n",
    "    :return: dataframe to append (current day state data structure)\n",
    "    '''\n",
    "    # latest reported date assumed equal to all states/obs_types/obs_cat\n",
    "    last_date = pd.to_datetime(st_ts_df.time_period).max()\n",
    "    # filter range of days\n",
    "    cut_date_0 = (last_date - pd.to_timedelta(x, unit='d')).strftime('%Y-%m-%d')\n",
    "    cut_date_1 = (last_date - pd.to_timedelta(y, unit='d')).strftime('%Y-%m-%d')\n",
    "    # obs_cat is confirmed\n",
    "    obs_cat = 'confirmed'\n",
    "    # query state timeseries (delta confirmed in range of days)\n",
    "    query = \"obs_type == 'delta' & obs_cat == @obs_cat  & time_period > @cut_date_0 & time_period <= @cut_date_1\"\n",
    "    # deltaX_Y calculated\n",
    "    deltaX_Y_calc = st_ts_df.query(query).groupby('state').agg({'val': 'sum'}).reset_index()\n",
    "    # obs_type is deltaX_Y\n",
    "    obs_type = f\"delta{x}_{y}\"\n",
    "    # fill cols obs_cat, obs_type with constants (match current day state data structure)\n",
    "    deltaX_Y_calc['obs_cat'] = obs_cat\n",
    "    deltaX_Y_calc['obs_type'] = obs_type\n",
    "#     # reorder column 'val'\n",
    "#     val_c = deltaX_Y_calc.val\n",
    "#     deltaX_Y_calc.drop('val', axis = 1, inplace = True)\n",
    "#     deltaX_Y_calc.insert(3, 'val', val_c)\n",
    "    return deltaX_Y_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function test OK: match delta7 with delta7_0\n",
    "# query_d7c = \"obs_type == 'delta7' & obs_cat == 'confirmed'\"\n",
    "# pd.concat(\n",
    "#     [\n",
    "#         conf_st_deltaX_Y(long_ts_df, x=7, y=0).set_index('state'),\n",
    "#         long_st_df.query(query_d7c).set_index('state').val,\n",
    "#     ], axis = 1\n",
    "# ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas concat works with different column order (keeps first)\n",
    "long_st_df = pd.concat([long_st_df, conf_st_deltaX_Y(long_ts_df)], ignore_index=True)\n",
    "long_st_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(long_st_df.state.unique())} states:\")\n",
    "print(long_st_df.state.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### State metadata\n",
    "Metadata at state level, **important** information here: population of the state (based on NCP projections)\n",
    "\n",
    "To join eventually into state data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter state metadata from json data\n",
    "json_meta_st = {\n",
    "    key_1: {\n",
    "        key_2: response_data.json()[key_1][key_2]\n",
    "        for key_2 in response_data.json()[key_1] if key_2 == 'meta'\n",
    "    } for key_1 in response_data.json()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json_meta_st and normalize\n",
    "wide_meta_st_df = pd.json_normalize(json_meta_st, max_level=2)\n",
    "# build temporary long format from column names\n",
    "long_meta_st_df = wide_meta_st_df.columns.str.split(\".\", expand=True).droplevel(1).to_frame(\n",
    "    index=False, name=[\"state\", \"column\"]\n",
    ")\n",
    "long_meta_st_df[\"val\"] = wide_meta_st_df.values[0]\n",
    "# pivot temporary long into state metadata table\n",
    "meta_st_df = long_meta_st_df.pivot(index='state', columns='column', values='val').reset_index()\n",
    "# delete index name `column` from pivot\n",
    "meta_st_df.rename_axis(None, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un nest state metadata tested column\n",
    "tested_df = meta_st_df.tested.apply(pd.Series).rename(\n",
    "    columns={\"date\": \"test_date\", \"source\": \"test_source\"}\n",
    ")\n",
    "# concat back to metadata\n",
    "meta_st_df = pd.concat([meta_st_df, tested_df], axis = 1).drop('tested', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un nest state metadata vaccinated column if present\n",
    "if 'vaccinated' in meta_st_df.columns:\n",
    "    vac_df = meta_st_df.vaccinated.apply(pd.Series).rename(\n",
    "        columns={\"date\": \"vaccinated_date\", \"source\": \"vaccinated_source\"}\n",
    "    )\n",
    "    # concat back to metadata\n",
    "    meta_st_df = pd.concat([meta_st_df, vac_df], axis = 1).drop('vaccinated', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_st_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Export State Metadata (code commented to deploy in Binder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"./excel/state_meta.xlsx\"\n",
    "# meta_st_df.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare State delta7 with $\\sum{(\\mathrm{time-series})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excercise on state level (filter delta confirmed)\n",
    "set_type = 'delta'\n",
    "query = \"obs_type == @set_type & obs_cat == 'confirmed'\"\n",
    "d_conf_ts = long_ts_df.query(query)\n",
    "# cutting date query\n",
    "max_time = pd.to_datetime(d_conf_ts.time_period).max()\n",
    "cut_date = (max_time - pd.to_timedelta(7, unit='d')).strftime('%Y-%m-%d')\n",
    "query_t = \"time_period > @cut_date\"\n",
    "# delta7 a pelo\n",
    "delta7_calc = d_conf_ts.query(query_t).groupby('state').agg({'val': 'sum'}).rename(\n",
    "    columns={\"val\": \"beto_calc\"}\n",
    ")\n",
    "# add delta7 from both API state time-series and current\n",
    "# max_time = max_time - pd.to_timedelta(1, unit='d')\n",
    "query_ts = \"obs_type == 'delta7' & obs_cat == 'confirmed' & time_period == @max_time.strftime('%Y-%m-%d')\"\n",
    "set_type = 'delta7'\n",
    "comp_delta7 = pd.concat(\n",
    "    [\n",
    "        delta7_calc,\n",
    "        long_ts_df.query(query_ts).set_index('state').val,\n",
    "        long_st_df.query(query).set_index('state').val,\n",
    "    ], axis = 1\n",
    ").reset_index()\n",
    "comp_delta7.columns = [comp_delta7.columns[0], comp_delta7.columns[1], 'val_ts', 'val_st']\n",
    "comp_delta7\n",
    "# print(comp_delta7)\n",
    "# max_time = max_time + pd.to_timedelta(1, unit='d')\n",
    "# print(long_ts_df.query(query_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare State delta21_14 with $\\sum{(\\mathrm{time-series})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excercise on state level (filter delta confirmed)\n",
    "set_type = 'delta'\n",
    "query = \"obs_type == @set_type & obs_cat == 'confirmed'\"\n",
    "d_conf_ts = long_ts_df.query(query)\n",
    "# cutting date query\n",
    "max_time = pd.to_datetime(d_conf_ts.time_period).max()\n",
    "cut_date_0 = (max_time - pd.to_timedelta(21, unit='d')).strftime('%Y-%m-%d')\n",
    "cut_date_1 = (max_time - pd.to_timedelta(14, unit='d')).strftime('%Y-%m-%d')\n",
    "query_t = \"time_period > @cut_date_0 & time_period <= @cut_date_1\"\n",
    "# delta21_14 a pelo\n",
    "delta21_14_calc = d_conf_ts.query(query_t).groupby('state').agg({'val': 'sum'}).rename(\n",
    "    columns={\"val\": \"beto_calc\"}\n",
    ")\n",
    "# add delta21_14 from API state current\n",
    "max_time = max_time - pd.to_timedelta(1, unit='d')\n",
    "set_type = 'delta21_14'\n",
    "comp_delta21_14 = pd.concat(\n",
    "    [\n",
    "        delta21_14_calc,\n",
    "        long_st_df.query(query).set_index('state').val,\n",
    "    ], axis = 1\n",
    ").reset_index().rename(columns={\"val\": \"val_st\"})\n",
    "comp_delta21_14\n",
    "# print(comp_delta21_14)\n",
    "# (abs(comp_delta21_14.beto_calc-comp_delta21_14.val_st)/comp_delta21_14.val_st*100).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### District data\n",
    "Eventually join into state data and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter district data and metadata from json data\n",
    "json_ds = {\n",
    "    key_1: {\n",
    "        key_2: response_data.json()[key_1][key_2]\n",
    "        for key_2 in response_data.json()[key_1] if key_2 == 'districts'\n",
    "    } for key_1 in response_data.json()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json_ds and normalize - use custom separator: district names have points!\n",
    "start_time = time.time()\n",
    "wide_ds_df = pd.json_normalize(json_ds, max_level=4, sep='//')\n",
    "total_sec = time.time() - start_time\n",
    "print(f\"{round(total_sec,1)} secs execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build long format from column names (renames as desired)\n",
    "long_ds_df = wide_ds_df.columns.str.split(\"//\", expand=True).droplevel(1).to_frame(\n",
    "    index=False, name=[\"state\", \"district\", \"obs_type\", \"obs_cat\"]\n",
    ")\n",
    "# add values from series\n",
    "long_ds_df[\"val\"] = wide_ds_df.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter metadata in temporary long format\n",
    "filter_meta = long_ds_df.obs_type == 'meta'\n",
    "long_meta_ds_df = long_ds_df[filter_meta]\n",
    "# district data in long format (drop metadata)\n",
    "long_data_ds_df = long_ds_df.drop(long_meta_ds_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Use data-all to compute delta14_7 for districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use data-all range dataframe to compute delta14_7\n",
    "ds_delta_14_7 = long_ds_range_df.groupby(['state', 'district']).agg({'val': 'sum'}).reset_index()\n",
    "# fill cols obs_cat, obs_type with constants (match current day district data structure)\n",
    "ds_delta_14_7['obs_cat'] = 'confirmed'\n",
    "ds_delta_14_7['obs_type'] = 'delta14_7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas concat works with different column order (keeps first)\n",
    "long_data_ds_df = pd.concat([long_data_ds_df, ds_delta_14_7], ignore_index=True)\n",
    "long_data_ds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function test OK: match delta7 with delta7_0 in districts\n",
    "# query_d7c = \"obs_type == 'delta7' & obs_cat == 'confirmed'\"\n",
    "# trunc_json = conf_ds_deltaX_Y(response_all.json(), 7, 0)\n",
    "# wide_ds_7_0_df = pd.json_normalize(trunc_json, sep='//')\n",
    "# long_ds_7_0_df = wide_ds_7_0_df.columns.str.split(\"//\", expand=True).to_frame(\n",
    "#     index=False, name=[\"time_period\", \"state\", \"district\"]\n",
    "# )\n",
    "# long_ds_7_0_df[\"val\"] = wide_ds_7_0_df.values[0]\n",
    "# pd.concat(\n",
    "#     [\n",
    "#         long_ds_7_0_df.groupby(['state', 'district']).agg({'val': 'sum'}),\n",
    "#         long_data_ds_df.query(query_d7c).set_index(['state', 'district']).val,\n",
    "#     ], axis = 1\n",
    "# ).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### District metadata\n",
    "Metadata at district level, **important** and **outdated** information: population of the district (based on 2011 census)\n",
    "\n",
    "**Note**: district names could be repeated among states\n",
    "\n",
    "To join eventually into state data and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot temporary long into district metadata table\n",
    "meta_ds_df = long_meta_ds_df.drop(columns='obs_type').set_index(\n",
    "    ['state', 'district', 'obs_cat']\n",
    ").unstack(level=-1).reset_index(col_level=1).droplevel(level=0, axis=1).rename_axis(None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un nest district tested column\n",
    "ds_tested_df = meta_ds_df.tested.apply(pd.Series).drop(0, axis = 1).rename(\n",
    "    columns={\"date\": \"test_date\", \"source\": \"test_source\"}\n",
    ")\n",
    "# concat back to metadata\n",
    "meta_ds_df = pd.concat([meta_ds_df, ds_tested_df], axis = 1).drop('tested', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un nest district vaccinated column\n",
    "ds_vac_df = meta_ds_df.vaccinated.apply(pd.Series).drop(0, axis = 1).rename(\n",
    "    columns={\"date\": \"vaccinated_date\"}\n",
    ")\n",
    "# concat back to metadata\n",
    "meta_ds_df = pd.concat([meta_ds_df, ds_vac_df], axis = 1).drop('vaccinated', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_ds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Export District Metadata (code commented to deploy in Binder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"./excel/district_meta.xlsx\"\n",
    "# meta_ds_df.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA: hospital bed occupancy\n",
    "Hospital bed occupany as reported in state bulletins (`csv` file from):\n",
    "\n",
    "https://api.covid19india.org/csv/latest/statewise_tested_numbers_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_url = \"https://api.covid19india.org/csv/latest/statewise_tested_numbers_data.csv\"\n",
    "st_bulletin_df = pd.read_csv(csv_url, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible columns to explore\n",
    "bed_occup_col = [\n",
    "    'People on ICU Beds',\n",
    "    'Total Num ICU Beds',\n",
    "    'Beds Occupied(Normal/Isolation)',\n",
    "    'Total Num Beds (Normal/Isolation)',\n",
    "    'People on O2 Beds',\n",
    "    'Total Num of O2 Beds',\n",
    "    'People on Ventilator',\n",
    "    'Total Num Ventilators',\n",
    "]\n",
    "st_bulletin_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current week data vis\n",
    "Based on these situation analysis indicators:\n",
    "\n",
    "|  |  |\n",
    "| --- | --- |\n",
    "| <img src=\"https://drive.google.com/uc?export=view&id=1X1hVR5y00vprU1jFT20nSP3Jc41jVsWY\" width=\"200\"> | <img src=\"https://drive.google.com/uc?export=view&id=1saMjeevjiVlv_Dq7BNRNUgKdOApjwFeS\" width=\"200\"> |\n",
    "| <img src=\"https://drive.google.com/uc?export=view&id=10frXzVNHFAFNW1GrErj3QwKZRZGPZl9A\" width=\"200\"> | <img src=\"https://drive.google.com/uc?export=view&id=1AdDqL3kVyjaepYR8N9t6Q5Y2iwaXCkYK\" width=\"200\"> |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropdowns: state/district, situation indicators\n",
    "geo_level = ['State', 'District']\n",
    "dd_level = dcc.Dropdown(\n",
    "    id=\"my_level\",\n",
    "    options=[\n",
    "        {\"label\": value, \"value\": key}\n",
    "        for key, value in zip(geo_level, geo_level)\n",
    "    ],\n",
    "    value='State'\n",
    ")\n",
    "sit_ind = [\n",
    "    'Case Incidence',\n",
    "    'Percent change in cases',\n",
    "    'Test Positivity Rate (TPR)',\n",
    "    'Case Fatality Ratio (CFR)',\n",
    "]\n",
    "dd_ind = dcc.Dropdown(\n",
    "    id=\"my_ind\",\n",
    "    options=[\n",
    "        {\"label\": value, \"value\": key}\n",
    "        for key, value in zip(sit_ind, sit_ind)\n",
    "    ],\n",
    "    value='Case Incidence'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build App: current day\n",
    "app_c = JupyterDash(__name__, external_stylesheets=external_stylesheets)\n",
    "# App Layout\n",
    "app_c.layout = html.Div([\n",
    "    html.H2(\"Situation Analysis Framework\"),\n",
    "    html.H6(\"Switch State/District and select Indicator\"),\n",
    "    html.Div([\n",
    "        html.Div(\n",
    "            [\"Switch:\", dd_level],\n",
    "            style={'width': '30%', 'display': 'inline-block'},\n",
    "        ),\n",
    "        html.Div(\n",
    "            [\"Situation Indicator:\", dd_ind],\n",
    "            style={'width': '65%', 'display': 'inline-block'},\n",
    "        ),\n",
    "    ]),\n",
    "    html.Br(),\n",
    "    dcc.Graph(id='bar-plot')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback to update graph\n",
    "@app_c.callback(\n",
    "    Output(\"bar-plot\", \"figure\"),\n",
    "    Input(\"my_level\", \"value\"),\n",
    "    Input(\"my_ind\", \"value\"),\n",
    ")\n",
    "def plot_indicator(geo_lev, indicator):\n",
    "    # don't return plot if any missing values\n",
    "    if any([not geo_lev, not indicator]):\n",
    "        return {}\n",
    "    else:\n",
    "        # data/metadata level\n",
    "        data = long_st_df if geo_lev == 'State' else long_data_ds_df\n",
    "        meta = meta_st_df if geo_lev == 'State' else meta_ds_df\n",
    "        # left join data/meta\n",
    "        key_join = \"state\" if geo_lev == 'State' else [\"state\", \"district\"]\n",
    "        data_meta_df = data.merge(meta, on=key_join, how=\"left\", sort=False)\n",
    "        query = \"obs_cat == 'confirmed'\"\n",
    "        df = data_meta_df.query(query).set_index(key_join)\n",
    "        obs_d07 = df.obs_type == 'delta7'\n",
    "        query_t = \"obs_cat == 'tested'\"\n",
    "        df_t = data_meta_df.query(query_t).set_index(key_join)\n",
    "        obs_t_d07 = df_t.obs_type == 'delta7'\n",
    "        query_d = \"obs_cat == 'deceased'\"\n",
    "        df_d = data_meta_df.query(query_d).set_index(key_join)\n",
    "        obs_d_d07 = df_d.obs_type == 'delta7'\n",
    "        \n",
    "        if \"change\" in indicator:\n",
    "            obs_d14 = df.obs_type == 'delta14_7'\n",
    "            # assumes no delta zeros or instead Inf will result\n",
    "            ind_calc = (df.val[obs_d07] - df.val[obs_d14]) / df.val[obs_d07] * 100\n",
    "        elif \"Incidence\" in indicator:\n",
    "            # newly confirmed per million population (per week --> delta7)\n",
    "            ind_calc = df.val[obs_d07] * 1e6 / df.population[obs_d07]\n",
    "        elif \"Fatality\" in indicator:\n",
    "            # total deaths over total confirmed\n",
    "            # assumes no delta zeros or instead Inf will result\n",
    "            ind_calc = df_d.val[obs_d_d07] / df.val[obs_d07] * 100\n",
    "        else:\n",
    "            # test positivity rate (per week --> delta7)\n",
    "            # assumes no delta zeros or instead Inf will result\n",
    "            ind_calc = df.val[obs_d07] / df_t.val[obs_t_d07] * 100\n",
    "        \n",
    "        fig = px.bar(\n",
    "                ind_calc.reset_index().rename(columns={0: \"val\"}),\n",
    "                x=geo_lev.lower(),\n",
    "                y=\"val\",\n",
    "            ).update_layout(xaxis={'categoryorder':'total descending'})\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run app and display result inline in the notebook\n",
    "app_c.run_server(mode='inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Case Incidence for external analysis (excel export commented to deploy in Binder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join data/meta\n",
    "data_meta_df = long_st_df.merge(meta_st_df, on=\"state\", how=\"left\", sort=False)\n",
    "query = \"obs_cat == 'confirmed'\"\n",
    "df = data_meta_df.query(query).set_index(\"state\")\n",
    "obs_d07 = df.obs_type == 'delta7'\n",
    "# newly confirmed per million population (per week --> delta7)\n",
    "ind_calc = df.val[obs_d07] * 1e6 / df.population[obs_d07]\n",
    "st_inc_df = (\n",
    "    pd.concat([ind_calc, df[['val', 'population']][obs_d07]], axis = 1)\n",
    ").reset_index().rename(columns={0: \"case_inc\", \"val\": \"delta7\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join data/meta\n",
    "data_meta_df = long_data_ds_df.merge(meta_ds_df, on=[\"state\", \"district\"], how=\"left\", sort=False)\n",
    "query = \"obs_cat == 'confirmed'\"\n",
    "df = data_meta_df.query(query).set_index([\"state\", \"district\"])\n",
    "obs_d07 = df.obs_type == 'delta7'\n",
    "# newly confirmed per million population (per week --> delta7)\n",
    "ind_calc = df.val[obs_d07] * 1e6 / df.population[obs_d07]\n",
    "ds_inc_df = (\n",
    "    pd.concat([ind_calc, df[['val', 'population']][obs_d07]], axis = 1)\n",
    ").reset_index().rename(columns={0: \"case_inc\", \"val\": \"delta7\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"./excel/case_incidence.xlsx\"\n",
    "# with pd.ExcelWriter(file_path) as writer:\n",
    "#     st_inc_df.to_excel(writer, sheet_name='state', index=False)\n",
    "#     ds_inc_df.to_excel(writer, sheet_name='district', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drafts test/check\n",
    "Commented code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test in place a ver\n",
    "# geo_lev = 'State' # 'District' #\n",
    "# indicator = 'Case Incidence' # 'Percent change in cases' #\n",
    "# # data/metadata level\n",
    "# data = long_st_df if geo_lev == 'State' else long_data_ds_df\n",
    "# meta = meta_st_df if geo_lev == 'State' else meta_ds_df\n",
    "# # left join data/meta\n",
    "# key_join = \"state\" if geo_lev == 'State' else [\"state\", \"district\"]\n",
    "# data_meta_df = data.merge(meta, on=key_join, how=\"left\", sort=False)\n",
    "# query = \"obs_cat == 'confirmed'\"\n",
    "# df = data_meta_df.query(query).set_index(key_join)\n",
    "# obs_d07 = df.obs_type == 'delta7'\n",
    "# if \"change\" in indicator:\n",
    "#     obs_d14 = df.obs_type == 'delta21_14'\n",
    "#     # assumes no delta zeros or instead Inf will result\n",
    "#     ind_calc = (df.val[obs_d07] - df.val[obs_d14]) / df.val[obs_d07] * 100\n",
    "# else:\n",
    "#     # newly confirmed per million population (per week)\n",
    "#     ind_calc = df.val[obs_d07] * 7e6 / df.population[obs_d07]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_st_df[long_st_df.state == 'MZ']\n",
    "# meta_st_df[meta_st_df.state == 'MZ']\n",
    "# 3894*7 / 1192000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Source CoWIN](https://dashboard.cowin.gov.in/)\n",
    "Is API documented?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yves shared link 1\n",
    "https://api.cowin.gov.in/api/v1/reports/v2/getPublicReports?state_id=&district_id=&date=2021-07-15\n",
    "\n",
    "- Check out structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API parameters\n",
    "st_id = \"\"\n",
    "ds_id = \"\"\n",
    "date = \"2021-07-21\"\n",
    "url = \"https://api.cowin.gov.in/api/v1/reports/v2/getPublicReports\"\n",
    "api_param = {\n",
    "    \"state_id\": st_id,\n",
    "    \"district_id\": ds_id,\n",
    "    \"date\": date,\n",
    "}\n",
    "response_cowi = requests.get(url, params=api_param)\n",
    "response_cowi.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys in data_structure levels\n",
    "if response_cowi.status_code == 200:\n",
    "    keys_1 = [key for key in response_cowi.json()]\n",
    "    print(f\"Keys @level 1:\\n{keys_1}\")\n",
    "    keys_2 = []\n",
    "    for key in keys_1:\n",
    "        # check keys for dicts or list of dicts\n",
    "        if isinstance(response_cowi.json()[key], dict):\n",
    "            keys_2.append(list(response_cowi.json()[key].keys()))\n",
    "        elif isinstance(response_cowi.json()[key], list):\n",
    "            keys_list = []\n",
    "            for elem in response_cowi.json()[key]:\n",
    "                keys_list.append(list(elem.keys()))\n",
    "            keys_2.append(keys_list)\n",
    "        else:\n",
    "            keys_2.append('None')\n",
    "    print(f\"Keys @level 2:\\n{keys_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if nested info at level 2\n",
    "data_types = []\n",
    "for i, key in enumerate(keys_1):\n",
    "    if isinstance(keys_2[i], list):\n",
    "        for j, elem in enumerate(keys_2[i]):            \n",
    "            # check not list of list\n",
    "            if not isinstance(elem, list):\n",
    "                data = response_cowi.json()[key][elem]\n",
    "                data_types.append(type(data))\n",
    "#                 print(type(data))\n",
    "            else:\n",
    "                for key_2 in elem:\n",
    "                    data = response_cowi.json()[key][j][key_2]\n",
    "                    data_types.append(type(data))\n",
    "#                     print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(data_types))\n",
    "data_types.count(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `topBlock` Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json and normalize\n",
    "wide_top_df = pd.json_normalize(response_cowi.json()['topBlock'])\n",
    "long_top_df = wide_top_df.columns.str.split(\".\", expand=True).to_frame(\n",
    "    index=False, name=[\"obs_type\", \"obs_cat\"]\n",
    ")\n",
    "long_top_df[\"val\"] = wide_top_df.values[0]\n",
    "long_top_df.set_index([\"obs_type\", \"obs_cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `vaccinationDoneByTime` Extraction\n",
    "\n",
    "Doesn't look relevant for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json and normalize\n",
    "vac_by_time_df = pd.json_normalize(response_cowi.json()['vaccinationDoneByTime'])\n",
    "vac_by_time_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `last7DaysRegistration` Extraction\n",
    "\n",
    "Doesn't look relevant for our analysis <!-- -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json and normalize\n",
    "reg7_df = pd.json_normalize(response_cowi.json()['last7DaysRegistration'])\n",
    "reg7_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `last30DaysAefi` Extraction\n",
    "\n",
    "**AEFI**: Adverse event following immunization\n",
    "\n",
    "Doesn't look relevant for our analysis <!-- -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json and normalize\n",
    "aefi30_df = pd.json_normalize(response_cowi.json()['last30DaysAefi'])\n",
    "aefi30_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `last5daySessionStatus` Extraction\n",
    "\n",
    "Doesn't look relevant for our analysis, *data length doesn't match key name* <!-- -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json and normalize\n",
    "ses5_df = pd.json_normalize(response_cowi.json()['last5daySessionStatus'])\n",
    "ses5_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `getBeneficiariesGroupBy` Extraction\n",
    "\n",
    "Data at state - *name not code* - level: `state_id` could be tested as API parameter if required\n",
    "\n",
    "<!-- Doesn't look relevant for our analysis, *data length doesn't match key name* -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json and normalize\n",
    "ben_df = pd.json_normalize(response_cowi.json()['getBeneficiariesGroupBy'])\n",
    "ben_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `aefiPercentage`: is this for the day or the total among time-series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{response_cowi.json()['aefiPercentage']} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yves shared link 2\n",
    "https://api.cowin.gov.in/api/v1/reports/v2/getVacPublicReports?state_id=&district_id=&date=2021-07-15\n",
    "\n",
    "- Check out structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API parameters\n",
    "st_id = \"\"\n",
    "ds_id = \"\"\n",
    "date = \"2021-07-21\"\n",
    "url = \"https://api.cowin.gov.in/api/v1/reports/v2/getVacPublicReports\"\n",
    "api_param = {\n",
    "    \"state_id\": st_id,\n",
    "    \"district_id\": ds_id,\n",
    "    \"date\": date,\n",
    "}\n",
    "response_cowi = requests.get(url, params=api_param)\n",
    "response_cowi.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys in data_structure levels\n",
    "if response_cowi.status_code == 200:\n",
    "    keys_1 = [key for key in response_cowi.json()]\n",
    "    print(f\"Keys @level 1:\\n{keys_1}\")\n",
    "    keys_2 = []\n",
    "    for key in keys_1:\n",
    "        # check keys for dicts or list of dicts\n",
    "        if isinstance(response_cowi.json()[key], dict):\n",
    "            keys_2.append(list(response_cowi.json()[key].keys()))\n",
    "        elif isinstance(response_cowi.json()[key], list):\n",
    "            keys_list = []\n",
    "            for elem in response_cowi.json()[key]:\n",
    "                keys_list.append(list(elem.keys()))\n",
    "            keys_2.append(keys_list)\n",
    "        else:\n",
    "            keys_2.append('None')\n",
    "    print(f\"Keys @level 2:\\n{keys_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if nested info at level 2\n",
    "data_types = []\n",
    "for i, key in enumerate(keys_1):\n",
    "    if isinstance(keys_2[i], list):\n",
    "        for j, elem in enumerate(keys_2[i]):            \n",
    "            # check not list of list\n",
    "            if not isinstance(elem, list):\n",
    "                data = response_cowi.json()[key][elem]\n",
    "                data_types.append(type(data))\n",
    "#                 print(type(data))\n",
    "            else:\n",
    "                for key_2 in elem:\n",
    "                    data = response_cowi.json()[key][j][key_2]\n",
    "                    data_types.append(type(data))\n",
    "#                     print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(data_types))\n",
    "data_types.count(dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
