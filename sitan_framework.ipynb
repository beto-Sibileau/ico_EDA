{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Situation Indicators for Covid-19 response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "from jupyter_dash import JupyterDash\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per state time-series json API\n",
    "url = \"https://api.covid19india.org/v4/min/timeseries.min.json\"\n",
    "response_ts = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json and normalize\n",
    "start_time = time.time()\n",
    "wide_ts_df = pd.json_normalize(response_ts.json())\n",
    "total_sec = time.time() - start_time\n",
    "print(f\"{round(total_sec,1)} secs execution\")\n",
    "\n",
    "# transform to long format\n",
    "long_ts_df = wide_ts_df.columns.str.split(\".\", expand=True).droplevel(1).to_frame(\n",
    "    index=False, name=[\"state\", \"time_period\", \"obs_type\", \"obs_cat\"]\n",
    ")\n",
    "long_ts_df[\"val\"] = wide_ts_df.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target states and districts current day data and metadata\n",
    "url = \"https://api.covid19india.org/v4/min/data.min.json\"\n",
    "response_data = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter state metadata and districts out from json data\n",
    "json_st = {\n",
    "    key_1: {\n",
    "        key_2: response_data.json()[key_1][key_2]\n",
    "        for key_2 in response_data.json()[key_1] if key_2 not in ['districts', 'meta']\n",
    "    } for key_1 in response_data.json()\n",
    "}\n",
    "\n",
    "# read json_st and normalize\n",
    "wide_st_df = pd.json_normalize(json_st)\n",
    "# build long format from column names structure (renames as desired)\n",
    "long_st_df = wide_st_df.columns.str.split(\".\", expand=True).to_frame(\n",
    "    index=False, name=[\"state\", \"obs_type\", \"obs_cat\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter states delta confirmed for the previous week --> delta14_7\n",
    "def conf_st_deltaX_Y(st_ts_df, x=14, y=7):\n",
    "    '''\n",
    "    :param st_ts_df: state data timeseries Covid19 India API\n",
    "    :param x: lower limit number of days (integer)\n",
    "    :param y: upper limit number of days (integer)\n",
    "    :return: dataframe to append (current day state data structure)\n",
    "    '''\n",
    "    # latest reported date assumed equal to all states/obs_types/obs_cat\n",
    "    last_date = pd.to_datetime(st_ts_df.time_period).max()\n",
    "    # filter range of days\n",
    "    cut_date_0 = (last_date - pd.to_timedelta(x, unit='d')).strftime('%Y-%m-%d')\n",
    "    cut_date_1 = (last_date - pd.to_timedelta(y, unit='d')).strftime('%Y-%m-%d')\n",
    "    # obs_cat is confirmed\n",
    "    obs_cat = 'confirmed'\n",
    "    # query state timeseries (delta confirmed in range of days)\n",
    "    query = \"obs_type == 'delta' & obs_cat == @obs_cat  & time_period > @cut_date_0 & time_period <= @cut_date_1\"\n",
    "    # deltaX_Y calculated\n",
    "    deltaX_Y_calc = st_ts_df.query(query).groupby('state').agg({'val': 'sum'}).reset_index()\n",
    "    # obs_type is deltaX_Y\n",
    "    obs_type = f\"delta{x}_{y}\"\n",
    "    # fill cols obs_cat, obs_type with constants (match current day state data structure)\n",
    "    deltaX_Y_calc['obs_cat'] = obs_cat\n",
    "    deltaX_Y_calc['obs_type'] = obs_type\n",
    "    return deltaX_Y_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas concat works with different column order (keeps first)\n",
    "long_st_df = pd.concat([long_st_df, conf_st_deltaX_Y(long_ts_df)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.covid19india.org/v4/min/data-all.min.json\"\n",
    "response_all = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our aim here --> districts delta confirmed if present for the previous week --> delta14_7\n",
    "def conf_ds_deltaX_Y(json_resp, x=14, y=7):\n",
    "    '''\n",
    "    Json normalize from json_resp is time-processing unfeasible\n",
    "    Thus, extract only 'delta confirmed' for all districts previous week\n",
    "    :param json_resp: json response from 'data-all' Covid19 India API\n",
    "    :param x: lower limit number of days (integer)\n",
    "    :param y: upper limit number of days (integer)\n",
    "    :return: truncated json, all districts data restricted to: prev. week delta confirmed\n",
    "    '''\n",
    "    # reported days series\n",
    "    dates = pd.Series(list(json_resp.keys()))\n",
    "    # latest reported date assumed equal to all districts\n",
    "    last_date = pd.to_datetime(dates).max()\n",
    "    # filter range of days\n",
    "    cut_date_0 = (last_date - pd.to_timedelta(x, unit='d')).strftime('%Y-%m-%d')\n",
    "    cut_date_1 = (last_date - pd.to_timedelta(y, unit='d')).strftime('%Y-%m-%d')\n",
    "    filter_x_y = (dates > cut_date_0) & (dates <= cut_date_1)\n",
    "    # loop through range of days and return data in nested dictionary\n",
    "    trunc_json = {}\n",
    "    for day in dates[filter_x_y]:\n",
    "        trunc_json[day] = {}\n",
    "        for st in json_resp[day]:\n",
    "            if 'districts' in json_resp[day][st]:\n",
    "                trunc_json[day][st] = {}\n",
    "                for ds in json_resp[day][st]['districts']:\n",
    "                    if 'delta' in json_resp[day][st]['districts'][ds]:\n",
    "                        if 'confirmed' in json_resp[day][st]['districts'][ds]['delta']:\n",
    "                            trunc_json[day][st][ds] = json_resp[day][st]['districts'][ds]['delta']['confirmed']\n",
    "    return trunc_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "trunc_json = conf_ds_deltaX_Y(response_all.json())\n",
    "total_sec = time.time() - start_time\n",
    "print(f\"{round(total_sec,1)} secs execution\")\n",
    "# normalize truncated json with range of days\n",
    "wide_ds_range_df = pd.json_normalize(trunc_json, sep='//')\n",
    "\n",
    "# build long format from column names (renames as desired)\n",
    "long_ds_range_df = wide_ds_range_df.columns.str.split(\"//\", expand=True).to_frame(\n",
    "    index=False, name=[\"time_period\", \"state\", \"district\"]\n",
    ")\n",
    "# add delta confirmed values from series\n",
    "long_ds_range_df[\"val\"] = wide_ds_range_df.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter state metadata from json data\n",
    "json_meta_st = {\n",
    "    key_1: {\n",
    "        key_2: response_data.json()[key_1][key_2]\n",
    "        for key_2 in response_data.json()[key_1] if key_2 == 'meta'\n",
    "    } for key_1 in response_data.json()\n",
    "}\n",
    "# filter district data and metadata from json data\n",
    "# TODO: filter out current day data\n",
    "json_ds = {\n",
    "    key_1: {\n",
    "        key_2: response_data.json()[key_1][key_2]\n",
    "        for key_2 in response_data.json()[key_1] if key_2 == 'districts'\n",
    "    } for key_1 in response_data.json()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json_meta_st and normalize\n",
    "wide_meta_st_df = pd.json_normalize(json_meta_st, max_level=2)\n",
    "# build temporary long format from column names\n",
    "long_meta_st_df = wide_meta_st_df.columns.str.split(\".\", expand=True).droplevel(1).to_frame(\n",
    "    index=False, name=[\"state\", \"column\"]\n",
    ")\n",
    "long_meta_st_df[\"val\"] = wide_meta_st_df.values[0]\n",
    "# pivot temporary long into state metadata table\n",
    "meta_st_df = long_meta_st_df.pivot(index='state', columns='column', values='val').reset_index()\n",
    "# delete index name `column` from pivot\n",
    "meta_st_df.rename_axis(None, axis=1, inplace=True)\n",
    "\n",
    "# un nest state metadata tested column\n",
    "tested_df = meta_st_df.tested.apply(pd.Series).rename(\n",
    "    columns={\"date\": \"test_date\", \"source\": \"test_source\"}\n",
    ")\n",
    "# concat back to metadata\n",
    "meta_st_df = pd.concat([meta_st_df, tested_df], axis = 1).drop('tested', axis = 1)\n",
    "\n",
    "# un nest state metadata vaccinated column if present\n",
    "if 'vaccinated' in meta_st_df.columns:\n",
    "    vac_df = meta_st_df.vaccinated.apply(pd.Series).rename(\n",
    "        columns={\"date\": \"vaccinated_date\", \"source\": \"vaccinated_source\"}\n",
    "    )\n",
    "    # concat back to metadata\n",
    "    meta_st_df = pd.concat([meta_st_df, vac_df], axis = 1).drop('vaccinated', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json_ds and normalize - use custom separator: district names have points!\n",
    "wide_ds_df = pd.json_normalize(json_ds, max_level=4, sep='//')\n",
    "# build long format from column names\n",
    "long_ds_df = wide_ds_df.columns.str.split(\"//\", expand=True).droplevel(1).to_frame(\n",
    "    index=False, name=[\"state\", \"district\", \"obs_type\", \"obs_cat\"]\n",
    ")\n",
    "# add values from series\n",
    "long_ds_df[\"val\"] = wide_ds_df.values[0]\n",
    "# filter metadata in temporary long format\n",
    "filter_meta = long_ds_df.obs_type == 'meta'\n",
    "long_meta_ds_df = long_ds_df[filter_meta]\n",
    "\n",
    "# district data in long format (drop metadata)\n",
    "long_data_ds_df = long_ds_df.drop(long_meta_ds_df.index)\n",
    "# use data-all range dataframe to compute delta14_7\n",
    "ds_delta_14_7 = long_ds_range_df.groupby(['state', 'district']).agg({'val': 'sum'}).reset_index()\n",
    "# fill cols obs_cat, obs_type with constants (match current day district data structure)\n",
    "ds_delta_14_7['obs_cat'] = 'confirmed'\n",
    "ds_delta_14_7['obs_type'] = 'delta14_7'\n",
    "# pandas concat works with different column order (keeps first)\n",
    "long_data_ds_df = pd.concat([long_data_ds_df, ds_delta_14_7], ignore_index=True)\n",
    "\n",
    "# pivot temporary long into district metadata table\n",
    "meta_ds_df = long_meta_ds_df.drop(columns='obs_type').set_index(\n",
    "    ['state', 'district', 'obs_cat']\n",
    ").unstack(level=-1).reset_index(col_level=1).droplevel(level=0, axis=1).rename_axis(None, axis=1)\n",
    "\n",
    "# un nest district tested column\n",
    "ds_tested_df = meta_ds_df.tested.apply(pd.Series).drop(0, axis = 1).rename(\n",
    "    columns={\"date\": \"test_date\", \"source\": \"test_source\"}\n",
    ")\n",
    "# concat back to metadata\n",
    "meta_ds_df = pd.concat([meta_ds_df, ds_tested_df], axis = 1).drop('tested', axis = 1)\n",
    "\n",
    "# un nest district vaccinated column if present\n",
    "if 'vaccinated' in meta_ds_df.columns:\n",
    "    ds_vac_df = meta_ds_df.vaccinated.apply(pd.Series).drop(0, axis = 1).rename(\n",
    "        columns={\"date\": \"vaccinated_date\"}\n",
    "    )\n",
    "    # concat back to metadata\n",
    "    meta_ds_df = pd.concat([meta_ds_df, ds_vac_df], axis = 1).drop('vaccinated', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current week data vis\n",
    "Based on these situation analysis indicators:\n",
    "\n",
    "|  |  |\n",
    "| --- | --- |\n",
    "| <img src=\"https://drive.google.com/uc?export=view&id=1X1hVR5y00vprU1jFT20nSP3Jc41jVsWY\" width=\"200\"> | <img src=\"https://drive.google.com/uc?export=view&id=1saMjeevjiVlv_Dq7BNRNUgKdOApjwFeS\" width=\"200\"> |\n",
    "| <img src=\"https://drive.google.com/uc?export=view&id=10frXzVNHFAFNW1GrErj3QwKZRZGPZl9A\" width=\"200\"> | <img src=\"https://drive.google.com/uc?export=view&id=1AdDqL3kVyjaepYR8N9t6Q5Y2iwaXCkYK\" width=\"200\"> |\n",
    "| <img src=\"https://drive.google.com/uc?export=view&id=1dg3qZfbjQFuxCyLsmTS6iLLD2BKT5yL2\" width=\"200\"> |  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect proxy configuration for JupyterHub or Binder\n",
    "JupyterDash.infer_jupyter_proxy_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropdowns: state/district, situation indicators\n",
    "geo_level = ['State', 'District']\n",
    "dd_level = dcc.Dropdown(\n",
    "    id=\"my_level\",\n",
    "    options=[\n",
    "        {\"label\": value, \"value\": key}\n",
    "        for key, value in zip(geo_level, geo_level)\n",
    "    ],\n",
    "    value='State'\n",
    ")\n",
    "sit_ind = [\n",
    "    'Case Incidence',\n",
    "    'Percent change in cases',\n",
    "    'Test Positivity Rate (TPR)',\n",
    "    'Case Fatality Ratio (CFR)',\n",
    "]\n",
    "dd_ind = dcc.Dropdown(\n",
    "    id=\"my_ind\",\n",
    "    options=[\n",
    "        {\"label\": value, \"value\": key}\n",
    "        for key, value in zip(sit_ind, sit_ind)\n",
    "    ],\n",
    "    value='Case Incidence'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "# Build App: current day\n",
    "app_c = JupyterDash(__name__, external_stylesheets=external_stylesheets)\n",
    "# App Layout\n",
    "app_c.layout = html.Div([\n",
    "    html.H2(\"Situation Analysis Framework\"),\n",
    "    html.H6(\"Switch State/District and select Indicator\"),\n",
    "    html.Div([\n",
    "        html.Div(\n",
    "            [\"Switch:\", dd_level],\n",
    "            style={'width': '30%', 'display': 'inline-block'},\n",
    "        ),\n",
    "        html.Div(\n",
    "            [\"Situation Indicator:\", dd_ind],\n",
    "            style={'width': '65%', 'display': 'inline-block'},\n",
    "        ),\n",
    "    ]),\n",
    "    html.Br(),\n",
    "    dcc.Graph(id='bar-plot')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback to update graph\n",
    "@app_c.callback(\n",
    "    Output(\"bar-plot\", \"figure\"),\n",
    "    Input(\"my_level\", \"value\"),\n",
    "    Input(\"my_ind\", \"value\"),\n",
    ")\n",
    "def plot_indicator(geo_lev, indicator):\n",
    "    # don't return plot if any missing values\n",
    "    if any([not geo_lev, not indicator]):\n",
    "        return {}\n",
    "    else:\n",
    "        # data/metadata level\n",
    "        data = long_st_df if geo_lev == 'State' else long_data_ds_df\n",
    "        meta = meta_st_df if geo_lev == 'State' else meta_ds_df\n",
    "        # left join data/meta\n",
    "        key_join = \"state\" if geo_lev == 'State' else [\"state\", \"district\"]\n",
    "        data_meta_df = data.merge(meta, on=key_join, how=\"left\", sort=False)\n",
    "        query = \"obs_cat == 'confirmed'\"\n",
    "        df = data_meta_df.query(query).set_index(key_join)\n",
    "        obs_d07 = df.obs_type == 'delta7'\n",
    "        query_t = \"obs_cat == 'tested'\"\n",
    "        df_t = data_meta_df.query(query_t).set_index(key_join)\n",
    "        obs_t_d07 = df_t.obs_type == 'delta7'\n",
    "        query_d = \"obs_cat == 'deceased'\"\n",
    "        df_d = data_meta_df.query(query_d).set_index(key_join)\n",
    "        obs_d_d07 = df_d.obs_type == 'delta7'\n",
    "        \n",
    "        if \"change\" in indicator:\n",
    "            obs_d14 = df.obs_type == 'delta14_7'\n",
    "            # assumes no delta zeros or instead Inf will result\n",
    "            ind_calc = (df.val[obs_d07] - df.val[obs_d14]) / df.val[obs_d07] * 100\n",
    "        elif \"Incidence\" in indicator:\n",
    "            # newly confirmed per million population (per week --> delta7)\n",
    "            ind_calc = df.val[obs_d07] * 1e6 / df.population[obs_d07]\n",
    "        elif \"Fatality\" in indicator:\n",
    "            # total deaths over total confirmed\n",
    "            # assumes no delta zeros or instead Inf will result\n",
    "            ind_calc = df_d.val[obs_d_d07] / df.val[obs_d07] * 100\n",
    "        else:\n",
    "            # test positivity rate (per week --> delta7)\n",
    "            # assumes no delta zeros or instead Inf will result\n",
    "            ind_calc = df.val[obs_d07] / df_t.val[obs_t_d07] * 100\n",
    "        \n",
    "        fig = px.bar(\n",
    "                ind_calc.reset_index().rename(columns={0: \"val\"}),\n",
    "                x=geo_lev.lower(),\n",
    "                y=\"val\",\n",
    "            ).update_layout(xaxis={'categoryorder':'total descending'})\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run app and display result inline in the notebook\n",
    "app_c.run_server(mode='external')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
